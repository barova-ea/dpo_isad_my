{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426489b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from cv2 import CascadeClassifier\n",
    "import time\n",
    "import PIL\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import pandas as pd\n",
    "from IPython.display import display, Image, clear_output\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.utils import np_utils\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80faae9c",
   "metadata": {},
   "source": [
    "Создание набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967ab90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт и просмотр изображения\n",
    "def viewImage(image, proba): \n",
    "    cv2.namedWindow(proba, cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(proba, image)\n",
    "    # cv2.waitKey(0) # добавить, если надо просматривать фото\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5d5187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# В папке pic находится набор фотографий разного размера с разным количеством людей на них.\n",
    "pictures = os.listdir('pic')\n",
    "face_detector = cv2.CascadeClassifier('haarcascade/haarcascade_frontalface_default.xml')\n",
    "n = 0\n",
    "k = 0\n",
    "while k < len(pictures):\n",
    "    # считываем по порядку все изображения\n",
    "    image = cv2.imread('pic/' + pictures[k])\n",
    "    if type(image) == np.ndarray:\n",
    "        image_copy = image.copy()\n",
    "        # при распознавании установим следующие параметры:\n",
    "        faces = face_detector.detectMultiScale(image, scaleFactor= 1.3, minNeighbors = 15, minSize=(60, 60))\n",
    "        # Добавим столбец в ndarray faces для создания массива с номером фото\n",
    "        column_to_be_added = np.array([i for i in range(1, len(faces) + 1)])\n",
    "        faces_result = np.column_stack((faces, column_to_be_added))\n",
    "        # создаем набор лиц\n",
    "        for (x, y, w, h, i) in faces_result:\n",
    "            # Вырезаем лица с нужным отступом      \n",
    "            cropped = image[y: y+h+10, x + int(w/2-(h+10)/2): x + int(w/2 + (h+10)/2)]           \n",
    "            # Приводим все фотографии к одному размеру\n",
    "            img_resize = cv2.resize(cropped, (128, 128), interpolation = cv2.INTER_AREA)\n",
    "            # Сохраняем в новой папке\n",
    "            cv2.imwrite('result/''pic'+str(n + k + i)+'.jpg', img_resize)         \n",
    "        print('на фото №', k+1, 'выбрано', i, 'лиц' )\n",
    "        n += len(faces) - 1    \n",
    "    else:        \n",
    "        print('error  foto/' + pictures[k])\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48941c11",
   "metadata": {},
   "source": [
    "Создаем dataframe, содержащий имя фотографии, пол и возраст изображенного человека"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b14c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определить лицо и нарисовать ограничивающую рамку лица\n",
    "def getFaceBox(net, frame, conf_threshold=0.7):\n",
    "    frameOpencvDnn = frame.copy()\n",
    "    frameHeight = frameOpencvDnn.shape[0]  # Высота - это количество строк в матрице\n",
    "    frameWidth = frameOpencvDnn.shape[1]  # Ширина - это количество столбцов в матрице\n",
    "    blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()  # Сеть проводит прямое распространение и обнаруживает лица\n",
    "    bboxes = []\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > conf_threshold:\n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "            bboxes.append([x1, y1, x2, y2])  # координаты ограничивающей рамки\n",
    "            cv2.rectangle(frameOpencvDnn, (x1, y1), (x2, y2), (0, 255, 0), int(round(frameHeight / 150)),\n",
    "                         8)  # rectangle(img, pt1, pt2, color[, thickness[, lineType[, shift]]]) -> img\n",
    "    return frameOpencvDnn, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d6b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сетевая модель и модель предварительного обучения\n",
    "faceProto = \"weights/opencv_face_detector.pbtxt\"\n",
    "faceModel = \"weights/opencv_face_detector_uint8.pb\"\n",
    "ageProto = \"weights/deploy_age.prototxt\"\n",
    "ageModel = \"weights/age_net.caffemodel\"\n",
    "genderProto = \"weights/gender_deploy.prototxt\"\n",
    "genderModel = \"weights/gender_net.caffemodel\"\n",
    "# Модель означает\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "ageList = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "genderList = ['Male', 'Female']\n",
    "# Загрузить сеть\n",
    "ageNet = cv2.dnn.readNet(ageModel, ageProto)\n",
    "genderNet = cv2.dnn.readNet(genderModel, genderProto)\n",
    "# Сеть и модель распознавания лиц\n",
    "faceNet = cv2.dnn.readNet(faceModel, faceProto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70bcd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем пустой датасет\n",
    "df_title = {'foto': [], 'gender': [], 'age': []}\n",
    "df = pd.DataFrame(df_title)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a97238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим набор данных, соответствующий полу и возрастному промежутку рассматриваемой модели\n",
    "pictures = os.listdir('result')\n",
    "k = 0\n",
    "padding = 20\n",
    "t = time.time()\n",
    "# Открыть фотографию\n",
    "while k < len(pictures):\n",
    "    frame = cv2.imread('result/' + pictures[k], cv2.IMREAD_UNCHANGED)\n",
    "    frameFace, bboxes = getFaceBox(faceNet, frame)\n",
    "    for bbox in bboxes:\n",
    "        # Извлечь лицо, обрамленное рамкой для обнаружения, и вернуть изображение лица\n",
    "        face = frame[max(0, bbox[1] - padding):min(bbox[3] + padding, frame.shape[0] - 1),\n",
    "                max(0, bbox[0] - padding):min(bbox[2] + padding, frame.shape[1] - 1)]\n",
    "        list_face = [] \n",
    "        blob = cv2.dnn.blobFromImage(face, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "        genderNet.setInput(blob)   # blob входит в сеть для определения пола\n",
    "        genderPreds = genderNet.forward()   # Определение пола для прямой передачи\n",
    "        gender = genderList[genderPreds[0].argmax()]   # Категория Вернуться к типу пола\n",
    "        if gender == 'Male':\n",
    "            gender_name = '1'\n",
    "        else:\n",
    "            gender_name = '0'\n",
    "        print(\"Фото №\", k+1)\n",
    "        print(\"Пол : {}, conf = {:.3f}\".format(gender, genderPreds[0].max()))\n",
    "        ageNet.setInput(blob)\n",
    "        agePreds = ageNet.forward()  # Определение возраста для прямой передачи\n",
    "        age = ageList[agePreds[0].argmax()] # Категория Вернуться к типу возраста\n",
    "        for j in range(len(ageList)):\n",
    "            if age == ageList[j]:\n",
    "                if j < 3:\n",
    "                    age_name = str(0)\n",
    "                    print('класс 0 - 0-16 - детство')\n",
    "                if j == 3:\n",
    "                    age_name = str(1)\n",
    "                    print('класс 1 - 17-34 - молодость')\n",
    "                if j == 4:\n",
    "                    age_name = str(2)\n",
    "                    print('класс 2 - 35-60 - зрелость')\n",
    "                if j > 4:\n",
    "                    age_name = str(3)\n",
    "                    print('класс 3 - 60+ - пожилой возраст')\n",
    "        print(\"Возраст : {}, conf = {:.3f}\".format(age, agePreds[0].max()))\n",
    "        label = \"{},{}\".format(gender, age)\n",
    "        cv2.putText(frameFace, label, (bbox[0], bbox[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2, cv2.LINE_AA)  \n",
    "        cv2.imwrite('res_finish_1/pic'+str(k+1)+'.jpg', frameFace)\n",
    "        list_face.append({'foto': pictures[k], 'gender': gender_name, 'age': age_name})\n",
    "        df = df.append(list_face) # добавление данных в датасет\n",
    "    print(\"time : {:.3f} ms\".format(time.time() - t))\n",
    "    k += 1\n",
    "print(gender_name)\n",
    "print(age_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3cc445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка классов датасета\n",
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f85457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a792f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание csv-файла\n",
    "df.to_csv('foto_frame_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d311b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Открытие csv как dataframe\n",
    "df = pd.read_csv('foto_frame_1.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6781b4f7",
   "metadata": {},
   "source": [
    "Создание модели сверточной нейронной сети для распознавания возраста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9264cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считываем изображения по имени, сохраняем в массив данные\n",
    "def foto_to_array(x_array, size):\n",
    "    x = np.zeros((len(x_array), size, size))  \n",
    "    i = 0\n",
    "    for name in x_array:\n",
    "        image = cv2.imread('result/' + name)\n",
    "        gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        x[i] = np.array(gray_img)\n",
    "        i += 1       \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a59153",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = foto_to_array(df['foto'].values, 128)\n",
    "y_new = df['age'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee9973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Делим тестовую и обучающую выборки\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_new, y_new, test_size = 0.25, random_state = 123)\n",
    "\n",
    "# В нашем случае входными значениями являются пиксели в изображении, которые имеют значение от 0 до 255.\n",
    "# Если значения входных данных находятся в слишком широком диапазоне, это может отрицательно повлиять на работу сети. \n",
    "# Желательно нормализовать данные\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# При определении класса применяем \"двоичную классификацию\": изображение либо принадлежит одному определённому классу, либо нет\n",
    "# Для унитарного кодирования используется команда Numpy to_categorical(). \n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "class_num = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36b47d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# количество классов, которые будем определять\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdf661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем пустую модель. Sequential — классическая модель в Keras:\n",
    "model_age = Sequential()\n",
    "\n",
    "# Первый слой модели - это сверточный слой. Принимает входные данные и пропускать их через сверточные фильтры.\n",
    "# - Количество каналов (фильтров):  32, \n",
    "# - размер фильтра:  (3 x 3), \n",
    "# - задаем форму входа (100*100 - размер фото, 1 - градации серого), \n",
    "# - отступы: padding = 'same' (то есть, мы не меняем размер изображения)\n",
    "# - функция активации: relu \n",
    "\n",
    "model_age.add(Conv2D(32, (3, 3), input_shape = (128, 128, 1), activation = 'relu', padding='same'))\n",
    "\n",
    "# Исключающий слой для предотвращения переобучения, который случайным образом устраняет соединения между слоями \n",
    "# 0,2 означает, что он отбрасывает 20% существующих соединений:\n",
    "\n",
    "model_age.add(Dropout(0.2))\n",
    "\n",
    "# Пакетная нормализация входных данных, поступающих в следующий слой. \n",
    "# Т.о. сеть всегда создает функции активации с тем же распределением, которое нам нужно:\n",
    "\n",
    "model_age.add(BatchNormalization())\n",
    "\n",
    "# Следующий сверточный слой, но размер фильтра увеличивается (сеть уже может изучать более сложные представления):\n",
    "\n",
    "model_age.add(Conv2D(64, (3, 3), activation = 'relu', padding='same'))\n",
    "\n",
    "# Основа рабочего процесса в первой части реализации CNN: свертка, активация, исключение, объединение.\n",
    "# Следующий шаг:\n",
    "# - Объединяющий слой - помогает сделать классификатор изображений более корректным, чтобы он мог изучать релевантные шаблоны. \n",
    "# - Исключение (Dropout) \n",
    "# - Пакетная нормализация\n",
    "\n",
    "model_age.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_age.add(Dropout(0.2))\n",
    "model_age.add(BatchNormalization())\n",
    "\n",
    "# Повторяем эти слои:\n",
    "\n",
    "model_age.add(Conv2D(128, (3, 3), activation = 'relu', padding='same'))\n",
    "model_age.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_age.add(Dropout(0.2))\n",
    "model_age.add(BatchNormalization())\n",
    "\n",
    "# После того, как закончили со сверточными слоями,нужно сжать данные. (и добавляем слой исключения снова)\n",
    "\n",
    "model_age.add(Flatten())\n",
    "model_age.add(Dropout(0.2))\n",
    "\n",
    "# Cоздаем первый плотно связанный слой (указываем количество нейронов в плотном слое)\n",
    "# Число нейронов в последующих слоях будет теперь уменьшаться, \n",
    "# в конечном итоге приближаясь к тому же числу нейронов, что и классы в наборе данных (в данном случае 3). \n",
    "# maxnorm - ограничение ядра может упорядочить данные в процессе обучения, помогает предотвратить переобучение.\n",
    "\n",
    "model_age.add(Dense(256, kernel_constraint=maxnorm(3)))\n",
    "model_age.add(Activation('relu'))\n",
    "model_age.add(Dropout(0.2))\n",
    "model_age.add(BatchNormalization())\n",
    "\n",
    "model_age.add(Dense(128, kernel_constraint=maxnorm(3)))\n",
    "model_age.add(Activation('relu'))\n",
    "model_age.add(Dropout(0.2))\n",
    "model_age.add(BatchNormalization())\n",
    "\n",
    "# В последнем слое мы уравниваем количество классов с числом нейронов. \n",
    "# Каждый нейрон представляет класс, поэтому на выходе этого слоя будет вектор из 3 нейронов, \n",
    "# каждый из которых хранит некоторую вероятность того, что рассматриваемое изображение принадлежит его классу.\n",
    "# Функция активации softmax выбирает нейрон с наибольшей вероятностью в качестве своего выходного значения, \n",
    "# предполагая, что изображение принадлежит именно этому классу:\n",
    "\n",
    "model_age.add(Dense(num_classes))\n",
    "model_age.add(Activation('softmax'))\n",
    "\n",
    "# количество эпох для обучения = ?\n",
    "# оптимизатор - настроит веса в сети так, чтобы приблизиться к точке с наименьшими потерями. \n",
    "# Алгоритм Адама является одним из наиболее часто используемых оптимизаторов\n",
    "\n",
    "\n",
    "optimizer = 'adam'\n",
    "\n",
    "# компилируем модель с выбранными параметрами. метрику для оценки = accuracy\n",
    "\n",
    "model_age.compile(loss ='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0327e0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_age.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4bcfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEED (симметричный блочный криптоалгоритм на основе Сети Фейстеля)\n",
    "seed = 21\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed8afc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаем число эпох обучения\n",
    "epochs = 100\n",
    "# epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e23a367",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(seed)\n",
    "model_history_age = model_age.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=epochs, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17128396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Точность модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa96f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# График точности модели\n",
    "plt.plot(model_history_age.history['accuracy'])\n",
    "plt.plot(model_history_age.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train', 'test'], loc = 'upper left')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2b550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# График функции потерь модели\n",
    "plt.plot(model_history_age.history['loss'])\n",
    "plt.plot(model_history_age.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train', 'test'], loc = 'upper left')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83fa5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение модели\n",
    "from keras.models import load_model\n",
    "model_age.save('model_age.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e503b947",
   "metadata": {},
   "source": [
    "Создание модели сверточной нейронной сети для распознавания пола"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291a6639",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = foto_to_array(df['foto'].values, 128)\n",
    "z_new = df['gender'].values\n",
    "\n",
    "#Делим тестовую и обучающую выборки\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_new, z_new, test_size = 0.25, random_state = 123)\n",
    "\n",
    "# В нашем случае входными значениями являются пиксели в изображении, которые имеют значение от 0 до 255.\n",
    "# Если значения входных данных находятся в слишком широком диапазоне, это может отрицательно повлиять на работу сети. \n",
    "# Желательно нормализовать данные\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# При определении класса применяем \"двоичную классификацию\": изображение либо принадлежит одному определённому классу, либо нет\n",
    "# Для унитарного кодирования используется команда Numpy to_categorical(). \n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "class_num = y_test.shape[1]\n",
    "\n",
    "# количество классов, которые будем определять\n",
    "num_classes = 2\n",
    "\n",
    "# Создаем пустую модель. Sequential — классическая модель в Keras:\n",
    "model_gender = Sequential()\n",
    "\n",
    "# Первый слой модели - это сверточный слой. Принимает входные данные и пропускать их через сверточные фильтры.\n",
    "# - Количество каналов (фильтров):  32, \n",
    "# - размер фильтра:  (3 x 3), \n",
    "# - задаем форму входа (100*100 - размер фото, 1 - градации серого), \n",
    "# - отступы: padding = 'same' (то есть, мы не меняем размер изображения)\n",
    "# - функция активации: relu \n",
    "\n",
    "model_gender.add(Conv2D(32, (3, 3), input_shape = (128, 128, 1), activation = 'relu', padding='same'))\n",
    "\n",
    "# Исключающий слой для предотвращения переобучения, который случайным образом устраняет соединения между слоями \n",
    "# 0,2 означает, что он отбрасывает 20% существующих соединений:\n",
    "\n",
    "model_gender.add(Dropout(0.2))\n",
    "\n",
    "# Пакетная нормализация входных данных, поступающих в следующий слой. \n",
    "# Т.о. сеть всегда создает функции активации с тем же распределением, которое нам нужно:\n",
    "\n",
    "model_gender.add(BatchNormalization())\n",
    "\n",
    "# Следующий сверточный слой, но размер фильтра увеличивается (сеть уже может изучать более сложные представления):\n",
    "\n",
    "model_gender.add(Conv2D(64, (3, 3), activation = 'relu', padding='same'))\n",
    "\n",
    "# Основа рабочего процесса в первой части реализации CNN: свертка, активация, исключение, объединение.\n",
    "# Следующий шаг:\n",
    "# - Объединяющий слой - помогает сделать классификатор изображений более корректным, чтобы он мог изучать релевантные шаблоны. \n",
    "# - Исключение (Dropout) \n",
    "# - Пакетная нормализация\n",
    "\n",
    "model_gender.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_gender.add(Dropout(0.2))\n",
    "model_gender.add(BatchNormalization())\n",
    "\n",
    "# Повторяем эти слои:\n",
    "\n",
    "model_gender.add(Conv2D(128, (3, 3), activation = 'relu', padding='same'))\n",
    "model_gender.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_gender.add(Dropout(0.2))\n",
    "model_gender.add(BatchNormalization())\n",
    "\n",
    "# После того, как закончили со сверточными слоями,нужно сжать данные. (и добавляем слой исключения снова)\n",
    "\n",
    "model_gender.add(Flatten())\n",
    "model_gender.add(Dropout(0.2))\n",
    "\n",
    "# Cоздаем первый плотно связанный слой (указываем количество нейронов в плотном слое)\n",
    "# Число нейронов в последующих слоях будет теперь уменьшаться, \n",
    "# в конечном итоге приближаясь к тому же числу нейронов, что и классы в наборе данных (в данном случае 3). \n",
    "# maxnorm - ограничение ядра может упорядочить данные в процессе обучения, помогает предотвратить переобучение.\n",
    "\n",
    "model_gender.add(Dense(256, kernel_constraint=maxnorm(3)))\n",
    "model_gender.add(Activation('relu'))\n",
    "model_gender.add(Dropout(0.2))\n",
    "model_gender.add(BatchNormalization())\n",
    "\n",
    "model_gender.add(Dense(128, kernel_constraint=maxnorm(3)))\n",
    "model_gender.add(Activation('relu'))\n",
    "model_gender.add(Dropout(0.2))\n",
    "model_gender.add(BatchNormalization())\n",
    "\n",
    "# В последнем слое мы уравниваем количество классов с числом нейронов. \n",
    "# Каждый нейрон представляет класс, поэтому на выходе этого слоя будет вектор из 3 нейронов, \n",
    "# каждый из которых хранит некоторую вероятность того, что рассматриваемое изображение принадлежит его классу.\n",
    "# Функция активации softmax выбирает нейрон с наибольшей вероятностью в качестве своего выходного значения, \n",
    "# предполагая, что изображение принадлежит именно этому классу:\n",
    "\n",
    "model_gender.add(Dense(num_classes))\n",
    "model_gender.add(Activation('softmax'))\n",
    "\n",
    "# количество эпох для обучения = ?\n",
    "# оптимизатор - настроит веса в сети так, чтобы приблизиться к точке с наименьшими потерями. \n",
    "# Алгоритм Адама является одним из наиболее часто используемых оптимизаторов\n",
    "\n",
    "\n",
    "optimizer = 'adam'\n",
    "\n",
    "# компилируем модель с выбранными параметрами. метрику для оценки = accuracy\n",
    "\n",
    "model_gender.compile(loss ='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "print(model_gender.summary())\n",
    "\n",
    "# SEED (симметричный блочный криптоалгоритм на основе Сети Фейстеля)\n",
    "seed = 21\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# Задаем число эпох обучения\n",
    "epochs = 100\n",
    "# epochs = 300\n",
    "\n",
    "numpy.random.seed(seed)\n",
    "model_history_gender = model_gender.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=epochs, batch_size=64)\n",
    "\n",
    "# Точность модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "# График точности модели\n",
    "plt.plot(model_history_gender.history['accuracy'])\n",
    "plt.plot(model_history_gender.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train', 'test'], loc = 'upper left')\n",
    "plt.show\n",
    "\n",
    "# График функции потерь модели\n",
    "plt.plot(model_history_gender.history['loss'])\n",
    "plt.plot(model_history_gender.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train', 'test'], loc = 'upper left')\n",
    "plt.show\n",
    "\n",
    "# Сохранение модели\n",
    "from keras.models import load_model\n",
    "model_gender.save('model_age.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4814f27",
   "metadata": {},
   "source": [
    "Работа модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d63c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Открываем модель\n",
    "model_1 = load_model('model_age.h5') # модель распознавания возраста\n",
    "model_2 = load_model('model_gender.h5') # модель распознавания пола"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b805fbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Работа модели на обучающей выборке\n",
    "def foto_to_array(x_array, size):\n",
    "    x = np.zeros((len(x_array), size, size))\n",
    "    i = 0\n",
    "    for name in x_array:\n",
    "        image = cv2.imread('result/' + name)\n",
    "        gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        x[i] = np.array(gray_img)\n",
    "        i += 1     \n",
    "    return x\n",
    "df = pd.read_csv('foto_frame.csv')\n",
    "x_new = foto_to_array(df['foto'].values, 128)\n",
    "y_new = df['age'].values\n",
    "z_new = df['gender'].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_new, y_new, test_size = 0.25, random_state = 123)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Случайный выбор фотографии\n",
    "use_samples = [1, 15, 48, 175]\n",
    "samples_to_predict = []\n",
    "\n",
    "# Создание изображения для образца\n",
    "for sample in use_samples:\n",
    "    reshaped_image = x_train[sample].reshape((128, 128))\n",
    "    plt.imshow(reshaped_image)\n",
    "    plt.show()\n",
    "    samples_to_predict.append(x_train[sample])\n",
    "\n",
    "samples_to_predict = np.array(samples_to_predict)\n",
    "\n",
    "# Генерирование прогноза для выборки\n",
    "predictions_age = model_1.predict(samples_to_predict)\n",
    "predictions_gender = model_2.predict(samples_to_predict)\n",
    "\n",
    "classes_age = np.argmax(predictions_age, axis = 1)\n",
    "age_name = ['0 - 16', '17-35', '36 - 60', '60+']\n",
    "age = age_name[classes_age[0]]\n",
    "print('Возраст: ', age)\n",
    "classes_gender = np.argmax(predictions_gender, axis = 1)\n",
    "gender_name = ['Мужчина', 'Женщина']\n",
    "gender = gender_name[classes_gender[0]]\n",
    "print('Пол: ', gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5a85e1",
   "metadata": {},
   "source": [
    "Работа модели на фотографии нескольких людей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bc5301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сетевая модель и модель предварительного обучения\n",
    "faceProto = \"weights/opencv_face_detector.pbtxt\"\n",
    "faceModel = \"weights/opencv_face_detector_uint8.pb\"\n",
    "ageProto = \"weights/deploy_age.prototxt\"\n",
    "ageModel = \"weights/age_net.caffemodel\"\n",
    "genderProto = \"weights/gender_deploy.prototxt\"\n",
    "genderModel = \"weights/gender_net.caffemodel\"\n",
    "ageNet = cv2.dnn.readNet(ageModel, ageProto)\n",
    "genderNet = cv2.dnn.readNet(genderModel, genderProto)\n",
    "faceNet = cv2.dnn.readNet(faceModel, faceProto)\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "ageList = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "genderList = ['Male', 'Female']\n",
    "\n",
    "# Определить лицо и нарисовать ограничивающую рамку лица\n",
    "def getFaceBox(net, frame, conf_threshold=0.7):\n",
    "    frameOpencvDnn = frame.copy()\n",
    "    frameHeight = frameOpencvDnn.shape[0]\n",
    "    frameWidth = frameOpencvDnn.shape[1]\n",
    "    blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    bboxes = []\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > conf_threshold:\n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "            bboxes.append([x1, y1, x2, y2])  # координаты ограничивающей рамки\n",
    "            cv2.rectangle(frameOpencvDnn, (x1, y1), (x2, y2), (0, 255, 0), int(round(frameHeight / 150)), 8)\n",
    "    return frameOpencvDnn, bboxes\n",
    "\n",
    "# Распознавание пола и возраста\n",
    "padding = 20\n",
    "t = time.time()\n",
    "frame = cv2.imread('имя файла.jpg', cv2.IMREAD_UNCHANGED)             \n",
    "frameFace, bboxes = getFaceBox(faceNet, frame) \n",
    "for bbox in bboxes:\n",
    "    face = frame[max(0, bbox[1] - padding):min(bbox[3] + padding, frame.shape[0] - 1),\n",
    "            max(0, bbox[0] - padding):min(bbox[2] + padding, frame.shape[1] - 1)]\n",
    "    img_resize = cv2.resize(face, (128, 128), interpolation = cv2.INTER_AREA)\n",
    "    gray_img = cv2.cvtColor(img_resize, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    samples_to_predict = []\n",
    "    samples_to_predict.append(gray_img)\n",
    "    samples_to_predict = np.array(samples_to_predict)\n",
    "    \n",
    "    predictions_age = model_1.predict(samples_to_predict)\n",
    "    predictions_gender = model_2.predict(samples_to_predict)\n",
    "\n",
    "    classes_age = np.argmax(predictions_age, axis = 1)\n",
    "    age_name = ['0 - 16', '17-35', '36 - 60', '60+']\n",
    "    age = age_name[classes_age[0]]\n",
    "    classes_gender = np.argmax(predictions_gender, axis = 1)\n",
    "    gender_name = ['Male', 'Female']\n",
    "    gender = gender_name[classes_gender[0]]\n",
    "         \n",
    "    label = \"{},{}\".format(gender, age)\n",
    "    cv2.putText(frameFace, label, (bbox[0], bbox[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.imwrite('новое имя файла.jpg', frameFace)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
